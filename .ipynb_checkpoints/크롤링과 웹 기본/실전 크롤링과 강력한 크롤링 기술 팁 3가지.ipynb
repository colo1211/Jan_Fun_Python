{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests \n",
    "from bs4 import BeautifulSoup "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(왕초보) - 클래스 소개\n",
      "(왕초보) - 블로그 개발 필요한 준비물 준비하기\n",
      "(왕초보) - Github pages 설정해서 블로그 첫 페이지 만들어보기\n",
      "(왕초보) - 초간단 페이지 만들어보기\n",
      "(왕초보) - 이쁘게 테마 적용해보기\n",
      "(왕초보) - 마크다운 기초 이해하고, 실제 나만의 블로그 페이지 만들기\n",
      "(왕초보) - 다양한 마크다운 기법 익혀보며, 나만의 블로그 페이지 꾸며보기\n",
      "(초급) - 강사가 실제 사용하는 자동 프로그램 소개 [2]\n",
      "(초급) - 필요한 프로그램 설치 시연 [5]\n",
      "(초급) - 데이터를 엑셀 파일로 만들기 [9]\n",
      "(초급) -     엑셀 파일 이쁘게! 이쁘게! [8]\n",
      "(초급) -     나대신 주기적으로 파이썬 프로그램 실행하기 [7]\n",
      "(초급) - 파이썬으로 슬랙(slack) 메신저에 글쓰기 [40]\n",
      "(초급) - 웹사이트 변경사항 주기적으로 체크해서, 메신저로 알람주기 [12]\n",
      "(초급) - 네이버 API 사용해서, 블로그에 글쓰기 [42]\n",
      "(중급) - 자동으로 쿠팡파트너스 API 로 가져온 상품 정보, 네이버 블로그/트위터에 홍보하기 [412]\n"
     ]
    }
   ],
   "source": [
    "res = requests.get('https://davelee-fun.github.io/blog/crawl_test')\n",
    "soup = BeautifulSoup(res.content,'html.parser')\n",
    "data = soup.find_all('li','course')\n",
    "for i in data : \n",
    "    print (i.get_text())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 크롤링 강력한 팁1 - 크롬 브라우저 활용하기\n",
    "* 오픈 크롬 브라우저\n",
    "* 오픈 크롬 개발자 모드\n",
    "* Command + Alt + i (맥)\n",
    "* Ctrl + Shift + i 또는 F12 (윈도우)\n",
    "* 마우스로 원하는 부분 선택"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 크롤링 강력한 팁2 - 추출한 것에서 또 추출하기\n",
    "* 1. find()로 더 크게 감싸는 HTML 태그로 추출하고\n",
    "* 2. 다시 추출된 데이터에서 find_all()로 원하는 부분을 추출\n",
    "*    추출된 데이터는 객체(object)입니다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 위에 출력한 data 값에 담긴 값 중 초급~ 부터만 가져올 것이다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(초급) - 강사가 실제 사용하는 자동 프로그램 소개 [2]\n",
      "(초급) - 필요한 프로그램 설치 시연 [5]\n",
      "(초급) - 데이터를 엑셀 파일로 만들기 [9]\n",
      "(초급) -     엑셀 파일 이쁘게! 이쁘게! [8]\n",
      "(초급) -     나대신 주기적으로 파이썬 프로그램 실행하기 [7]\n",
      "(초급) - 파이썬으로 슬랙(slack) 메신저에 글쓰기 [40]\n",
      "(초급) - 웹사이트 변경사항 주기적으로 체크해서, 메신저로 알람주기 [12]\n",
      "(초급) - 네이버 API 사용해서, 블로그에 글쓰기 [42]\n",
      "(중급) - 자동으로 쿠팡파트너스 API 로 가져온 상품 정보, 네이버 블로그/트위터에 홍보하기 [412]\n"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "\n",
    "res = requests.get('https://davelee-fun.github.io/blog/crawl_test')\n",
    "soup =BeautifulSoup(res.content, 'html.parser')\n",
    "\n",
    "data = soup.find('ul',id='dev_course_list') #두번째 섹션에 해당하는 데이터들 \n",
    "\n",
    "data_result = data.find_all('li','course') #두번째 영역에서 내가 추출하고 싶은 데이터를 또 추출한다. 팁2!!!!\n",
    "# find_all()은 자료를 리스트로 담는다. \n",
    "for i in data_result:\n",
    "    print (i.get_text())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 크롤링 강력한 팁3 - 파이썬 문자열 함수와 함께 쓰기\n",
    "### 데이터 전처리 (데이터를 내가 원하는 형태로 가다듬기) \n",
    "1. strip() 함수 사용해보기\n",
    "2. split() 함수 사용해보기"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 저 위에서 추출한 데이터들 중에 나는 제목 끝에 있는 댓글의 수를 삭제하고 싶다!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "강사가 실제 사용하는 자동 프로그램 소개\n",
      "필요한 프로그램 설치 시연\n",
      "데이터를 엑셀 파일로 만들기\n",
      "엑셀 파일 이쁘게! 이쁘게!\n",
      "나대신 주기적으로 파이썬 프로그램 실행하기\n",
      "파이썬으로 슬랙(slack) 메신저에 글쓰기\n",
      "웹사이트 변경사항 주기적으로 체크해서, 메신저로 알람주기\n",
      "네이버 API 사용해서, 블로그에 글쓰기\n",
      "자동으로 쿠팡파트너스 API 로 가져온 상품 정보, 네이버 블로그/트위터에 홍보하기\n"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "\n",
    "res = requests.get('https://davelee-fun.github.io/blog/crawl_test')\n",
    "soup =BeautifulSoup(res.content, 'html.parser')\n",
    "\n",
    "data = soup.find('ul',id='dev_course_list') #두번째 섹션에 해당하는 데이터들 \n",
    "\n",
    "data_result = data.find_all('li','course') #두번째 영역에서 내가 추출하고 싶은 데이터를 또 추출한다. 팁2!!!!\n",
    "# find_all()은 자료를 리스트로 담는다. \n",
    "for i in data_result:\n",
    "    print (i.get_text().split('[')[0].split('-')[1].strip()) \n",
    "    #"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### i.get_text().split('[')[0] -> 숫자를 삭제하기 위함 (문자열을 나눔)\n",
    "    [를 기준으로 리스트를 생성하고 0번째, 1번째 리스트 성분을 가진다. \n",
    "     여기서 spilt으로 나눈 후 [0]번째 만 출력하면 해결된다. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### .split('-')[1] -> (초급),(중급)을 삭제하기 위함 (문자열을 나눔)\n",
    "    -를 기준으로 리스트를 나누고 [1]번째 인자를 출력한다. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### .strip() -> 앞뒤 공백을 없애기 위함, 빈칸은 default 값으로 기본적으로 삭제"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 추출된 데이터 앞에 번호를 부여하고 싶으면"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 . 강사가 실제 사용하는 자동 프로그램 소개\n",
      "2 . 필요한 프로그램 설치 시연\n",
      "3 . 데이터를 엑셀 파일로 만들기\n",
      "4 . 엑셀 파일 이쁘게! 이쁘게!\n",
      "5 . 나대신 주기적으로 파이썬 프로그램 실행하기\n",
      "6 . 파이썬으로 슬랙(slack) 메신저에 글쓰기\n",
      "7 . 웹사이트 변경사항 주기적으로 체크해서, 메신저로 알람주기\n",
      "8 . 네이버 API 사용해서, 블로그에 글쓰기\n",
      "9 . 자동으로 쿠팡파트너스 API 로 가져온 상품 정보, 네이버 블로그/트위터에 홍보하기\n"
     ]
    }
   ],
   "source": [
    "for index,i in enumerate(data_result):\n",
    "    print (index+1,'.',i.get_text().split('[')[0].split('-')[1].strip()) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 연습!-> 이번엔 (왕초보) part를 크롤링 할것!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 :  클래스 소개\n",
      "2 :  블로그 개발 필요한 준비물 준비하기\n",
      "3 :  Github pages 설정해서 블로그 첫 페이지 만들어보기\n",
      "4 :  초간단 페이지 만들어보기\n",
      "5 :  이쁘게 테마 적용해보기\n",
      "6 :  마크다운 기초 이해하고, 실제 나만의 블로그 페이지 만들기\n",
      "7 :  다양한 마크다운 기법 익혀보며, 나만의 블로그 페이지 꾸며보기\n"
     ]
    }
   ],
   "source": [
    "res=requests.get('https://davelee-fun.github.io/blog/crawl_test')\n",
    "soup= BeautifulSoup(res.content,'html.parser')\n",
    "data = soup.find('ul',id='hobby_course_list')\n",
    "data_result= data.find_all('li','course')\n",
    "for index,i in enumerate(data_result):\n",
    "    print (index+1,':',i.get_text().split('-')[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### enumerate () 숫자 열거 함수"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
