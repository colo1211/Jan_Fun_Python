{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<h1 id=\"title\">[1]크롤링이란?</h1>\n",
      "[1]크롤링이란?\n",
      "[1]크롤링이란?\n"
     ]
    }
   ],
   "source": [
    "from bs4 import BeautifulSoup\n",
    "html = \"\"\"\n",
    "        <html> \n",
    "            <body> \n",
    "                    <h1 id='title'>[1]크롤링이란?</h1> \n",
    "                    <p class='cssstyle'>웹페이지에서 필요한 데이터를 추출하는 것</p> \n",
    "                    <p id='body' align='center'>파이썬을 중심으로 다양한 웹크롤링 기술 발달</p> \\\n",
    "            </body> \n",
    "        </html>\n",
    "\"\"\" # \"\"\"로 양옆으로 감싸면, \\를 생략 가능하다. \n",
    "soup = BeautifulSoup(html,\"html.parser\")\n",
    "# 태그로 검색 방법\n",
    "data = soup.find('h1') #찾기를 원하는 태그를 입력한다. .fing ('') \n",
    "print(data) #태그까지 뭉쳐서 추출된다.  \n",
    "print(data.string) #get_text()와 동일한 역할을 한다. = .string\n",
    "print(data.get_text())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### .find('body')는 None으로 출력된다. 한줄로 감싸고 있는 태그만 가능!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<p class=\"cssstyle\">웹페이지에서 필요한 데이터를 추출하는 것</p>\n",
      "웹페이지에서 필요한 데이터를 추출하는 것\n",
      "웹페이지에서 필요한 데이터를 추출하는 것\n"
     ]
    }
   ],
   "source": [
    "from bs4 import BeautifulSoup\n",
    "html = \"\"\"\n",
    "        <html> \n",
    "            <body> \n",
    "                    <h1 id='title'>[1]크롤링이란?</h1> \n",
    "                    <p class='cssstyle'>웹페이지에서 필요한 데이터를 추출하는 것</p> \n",
    "                    <p id='body' align='center'>파이썬을 중심으로 다양한 웹크롤링 기술 발달</p> \\\n",
    "            </body> \n",
    "        </html>\n",
    "\"\"\" # \"\"\"로 양옆으로 감싸면, \\를 생략 가능하다. \n",
    "soup = BeautifulSoup(html,\"html.parser\")\n",
    "# 태그로 검색 방법\n",
    "data = soup.find('p') #찾기를 원하는 태그를 입력한다. .fing ('') \n",
    "print(data) #태그까지 뭉쳐서 추출된다.  \n",
    "print(data.string) #get_text()와 동일한 역할을 한다. = .string\n",
    "print(data.get_text())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 나는 이제 '파이썬을 중심으로 다양한 웹크롤링 기술 발달'이라는 문장을 추출하고 싶다! 근데 앞에 p tag가 그대로 있어서 출력이 안된다!\n",
    "``` \n",
    "    실제로 웹페이지의 데이터들은 동일한 태그가 엄청나게 많이 존재한다!\n",
    "```\n",
    "#### 태그 안에 있는 클래스 속성을 활용하면 된다!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### p 태그 문장이 두 개인데 이 중에 하나를 선택하려면?\n",
    "###### 1. data = soup.find('p', class_='cssstyle')\n",
    "###### 2. data = soup.find('p', 'cssstyle')\n",
    "###### 3. data = soup.find('p', attrs = {'align': 'center'}) -> 속성을 활용하려면 클래스의 변수인 attrs (attributes) 변수에 속성을 사전형으로 담는다.\n",
    "###### 4. data = soup.find(id='body')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<p align=\"center\" id=\"body\">파이썬을 중심으로 다양한 웹크롤링 기술 발달</p>\n",
      "파이썬을 중심으로 다양한 웹크롤링 기술 발달\n"
     ]
    }
   ],
   "source": [
    "from bs4 import BeautifulSoup\n",
    "html = \"\"\"\n",
    "        <html> \n",
    "            <body> \n",
    "                    <h1 id='title'>[1]크롤링이란?</h1> \n",
    "                    <p class='cssstyle'>웹페이지에서 필요한 데이터를 추출하는 것</p> \n",
    "                    <p id='body' align='center'>파이썬을 중심으로 다양한 웹크롤링 기술 발달</p> \\\n",
    "            </body> \n",
    "        </html>\n",
    "\"\"\" # \"\"\"로 양옆으로 감싸면, \\를 생략 가능하다. \n",
    "soup = BeautifulSoup(html,\"html.parser\")\n",
    "# 태그로 검색 방법\n",
    "data = soup.find('p',attrs={'id':'body', 'align':'center'}) #찾기를 원하는 태그를 입력한다. .fing ('') \n",
    "print(data) #태그까지 뭉쳐서 추출된다.  \n",
    "print(data.get_text())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 근데 나, < p> 태그를 가진 모든 자료를 크롤링 해오고 싶은데 어떻게 하지? -> .find_all('p') \n",
    "# 이때 변수에 리스트 자료형으로 담긴다! "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[<p class=\"cssstyle\">웹페이지에서 필요한 데이터를 추출하는 것</p>, <p align=\"center\" id=\"body\">파이썬을 중심으로 다양한 웹크롤링 기술 발달</p>]\n",
      "웹페이지에서 필요한 데이터를 추출하는 것\n",
      "파이썬을 중심으로 다양한 웹크롤링 기술 발달\n"
     ]
    }
   ],
   "source": [
    "from bs4 import BeautifulSoup\n",
    "html = \"\"\"\n",
    "        <html> \n",
    "            <body> \n",
    "                    <h1 id='title'>[1]크롤링이란?</h1> \n",
    "                    <p class='cssstyle'>웹페이지에서 필요한 데이터를 추출하는 것</p> \n",
    "                    <p id='body' align='center'>파이썬을 중심으로 다양한 웹크롤링 기술 발달</p> \\\n",
    "            </body> \n",
    "        </html>\n",
    "\"\"\" # \"\"\"로 양옆으로 감싸면, \\를 생략 가능하다. \n",
    "soup = BeautifulSoup(html,\"html.parser\")\n",
    "# 태그로 검색 방법\n",
    "data = soup.find_all('p') # data에는 list자료형으로 담긴다! \n",
    "print (data)\n",
    "for i in data:# data변수에 리스트 자료형으로 담겼기떄문에 for문을 통해서 출력한다. \n",
    "    print (i.get_text())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 실제로 크롤리에서 가장 많이 사용되는 태그는 class이다! class는 css언어와 함께 이루어진 태그이다!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'BeatifulSoup' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-30-4f34b9814e21>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mbs4\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mBeautifulSoup\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[0mdata\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mrequests\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"http://happyforest.kidis.co.kr/index.php\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 5\u001b[1;33m \u001b[0mdata_1\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mBeatifulSoup\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcontent\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;34m'html.parser'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      6\u001b[0m \u001b[0mdata_2\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mdata1\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfind_add\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"meta\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      7\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mdata2\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'BeatifulSoup' is not defined"
     ]
    }
   ],
   "source": [
    "# 그냥 웹사이트 크롤링 연습! (강의 자료 아님)\n",
    "import requests \n",
    "from bs4 import BeautifulSoup\n",
    "data = requests.get(\"http://happyforest.kidis.co.kr/index.php\")\n",
    "data_1 = BeatifulSoup(data.content,'html.parser')\n",
    "data_2 = data1.find_add(\"meta\")\n",
    "for i in data2:\n",
    "    print(i.string)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
